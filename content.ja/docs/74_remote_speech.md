---
title: 音声を再生する
slug: lipsync
---
{{< hint info >}}
外部音声のリップシンクの機能は Plugin_Remote が提供しています。利用時はこのプラグインが有効になっているか確かめてください。
{{< /hint >}}

# 音声を再生する

外部モジュールから音声データを MMDAgent-EX へ渡し、リップシンク付きで再生することができます。実現のための方法がいくつか用意されています。以下、順に説明します。

## 方法１：ファイルで渡す

音声データをファイルに保存し、そのパスを MMDAgent-EX に指定して再生させる方法です。以下の手順で実行します。

- 音声合成（あるいは録音）した内容をオーディオファイルに保存
- そのパスを指定した **SPEAK** コマンドを MMDAgent-EX に送信

**SPEAK** コマンドの詳しい使い方については[「サウンドを再生する」で説明しています。](../sound/#%e9%9f%b3%e5%a3%b0%e5%86%8d%e7%94%9f-with-%e3%83%aa%e3%83%83%e3%83%97%e3%82%b7%e3%83%b3%e3%82%af) 

この方法はシンプルで簡単に実現できますが、外部プロセスとMMDAgent-EXが同じマシンの上で動いている必要があります。またリップシンクの内容は MMDAgent-EX にお任せです。また、再生する音声データはファイル単位で与えて再生する必要があり、長時間の音声ストリームの流し込みには使えません。

## 方法２：ソケットから音声データを流し込んで再生

[ソケット接続](../remote-control) を使って音声データをソケット経由で流し込む方法です。ソケット接続では通常テキストメッセージをMMDAgent-EXへ送れますが、以下に示す特定のヘッダを使うことで、音声データを同じソケットで送ることができます。[TCPIP](../remote-tcpip)と [WebSocket](../remote-websocket) のいずれでも動作します。

ソケットからの音声流し込みを使う場合、ソケット接続確立後に以下のようなメッセージをあらかじめ送っておいてください。1つ目は操作開始のメッセージで、2つ目はリップシンクさせるモデルのモデルエイリアス名を指定します。それぞれ `__AV_START\n` のように改行を入れて送ることを忘れないでください。

```text
__AV_START
__AV_SETMODEL,モデルエイリアス
```

続けて転送モードを指定します。ストリーミング音声をずっと送り続ける場合は `SNDSTRM\n` を送ります（終端はMMDAgent-EX側で自動検出）。そうではなく、予め区切られた音声を送る場合は`SNDFILE\n` を送ります（終端は送る側が明示的に指定）。

```text
(ストリーミングの場合)
SNDSTRM
(ファイル送信の場合)
SNDFILE
```

その後、オーディオデータを短いチャンクごとに区切ってソケットへ送信してください。１つのチャンクは、以下のようにヘッダが文字列 "`SND`" に続けて4桁(10進)のチャンク長（バイト数）、それに続けてデータ本体です。これを短いチャンク（1024バイト程度）ごとに連続して送ってください。データ本体で送る音声データのフォーマットは、エンコード無しの 16kHz, 16bit singed short, モノラル の PCM データである必要があります。

```text
SNDxxxxyyyyyyyyyyyyyyyyyyy....
  SND: ヘッダ
  xxxx: データ長（バイト数） 10進数
  yy...　データ長分の音声波形データ
```

ストリーミングの場合は上記の方法で短いチャンクごとに音声を送り続けてください。区切られた音声を送り込む場合は、終端まで送信し終えたら `SNDBRKS\n` を送って入力終了をMMDAgent-EXに伝えてください。

この音声伝送は通常のテキストメッセージと同じソケットでやりとりしており、合間にテキストメッセージを投げ込むことが可能です。

この方法は方法１に比べてプロトコルを実装しなければならず複雑ですが、外部プロセスとMMDAgent-EXが異なるマシンでも動作可能である利点があります。

## 方法３：口パクさせる

外部プロセスで完結して音声の再生まで行い、MMDAgent-EX には「口パク」だけさせることもできます。この場合、外部プロセスでリップシンク用のメッセージ **LYPSYNC_START** を作成し、音声を再生するタイミングに合わせて MMDAgent-EX に送ります。

**LIPSYNC_START** メッセージはリップシンクの実行を指示するメッセージです。第1引数は対象とするモデルのエイリアス名、第2引数がリップシンクの内容です。内容は、音素名および持続時間（単位はミリ秒）の列をカンマ区切りで指定します。

{{<message>}}
LIPSYNC_START|gene|sil,187,k,75,o,75,N,75,n,75,i,62,ch,75,i,87,w,100,a,87,sil,212
{{</message>}}

デフォルトで使える音素名は、Open JTalk で用いられている音素セットです。これは「リップシンク定義ファイル」を編集することで容易に変更・拡張可能です。

{{< details "リップシンク定義ファイルについて" close >}}

音素名の定義および各音素名からキャラクターのモーフへの変換規則が、MMDAgent-EX の実行ファイルがあるディレクトリの `AppData` フォルダ以下のファイル `lip.txt` で定義されています。一部を以下に示します。デフォルトでは Open JTalk の音素セットに対して「あ」「い」「う」「お」の4つのモーフの重み付き結合として表現するよう定義されています。これを編集、あるいは音素を追加することで、任意の音素列・モーフに拡張できます。

```text
# number of expressions
4
# expression names
あ
い
う
お
# number of phonemes
69
# phone names and interpolation weight
A   0.2 0.0 0.0 0.0
E   0.1 0.3 0.1 0.0
I   0.0 0.2 0.0 0.0
N   0.0 0.0 0.0 0.0
O   0.0 0.0 0.0 0.2
U   0.0 0.0 0.2 0.0
a   0.5 0.0 0.0 0.0
...
```

{{< /details >}}

MMDAgent-EX は **LIPSYNC_START** で送られた音素列を定義に従ってモーションに変換し、指定モデル上で再生を開始します。リップシンク開始時に **LIPSYNC_EVENT_START** が、終了時に **LIPSYNC_EVENT_STOP** が発行されます。

{{<message>}}
LIPSYNC_EVENT_START|(model alias)
LIPSYNC_EVENT_STOP|(model alias)
{{</message>}}

**LIPSYNC_STOP** で途中で中断もできます。

{{<message>}}
LIPSYNC_STOP|(model alias)
{{</message>}}

この方法の外部プロセスから見たメリット・デメリットです。

メリット：

- 再生が自前なので音声クオリティや再生デバイス等の MMDAgent-EX の仕様に制約されない
- リップシンク内容を制御できる
- 拡張性が高い

デメリット：

- 音素列と持続時間情報からリップシンク情報を自前で作成する必要がある
