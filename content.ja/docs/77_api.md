---
title: 外部API
slug: api
---

{{< hint ms >}}
本ページの以下の内容は、すべてムーンショット版のみの内容です。
{{< /hint >}}

# 外部API

外部プログラムから WebSocket または TCP/IP で接続して MMDAgent-EX を制御できます。制御のしくみとして以下の2つが用意されています。

- メッセージ投げ込み
- 外部API

MS版では、[標準的なメッセージの送受信](../remote-control/)に加えて、以下で説明するアバターとしての利用のための外部APIが定義されており、利用することができます。

## 仕様一覧

- メッセージは1つごとに改行 "\n" で区切って送信
- WebSocket の場合、ソケットの送信モードとしてテキストモードとバイナリモードのどちらでも動作する。ただし `SNDで始まるコマンド` については音声波形をバイナリで送るのでバイナリモードを使うこと。
- 接続終了時に全パラメータはリセットされる。次回接続には引き継がれない。

```text
__AV_START
　外部操作開始フラグ。これを受け取った MMDAgent-EX は、以後 __AV_END が来るまで受信した情報に従ってモデルの操作を行う。

__AV_END
　外部操作終了フラグ。これを受け取った MMDAgent-EX は、以後 __AV_START が来るまで外部操作を中断する。

__AV_SETMODEL,モデルエイリアス
　外部操作の対象とするモデルの名前。これを受け取った MMDAgent-EX は、指定された名前で動作しているモデルを以降の操作対象とする。

__AVCONF_DISABLEAUTOLIP,{NO|ARKIT|AU|ARKIT+AU|ALWAYS}
　音声伝送時の伝送音声からの自動リップシンクを行わない場面の指定。デフォルトは `NO` 、つまりリップシンクを常に行う。

__AV_ACTION,idx
　指定した対話アクションを再生する。アクションは番号(1から)で指定する。モデルでは shapemap で指定した対応モーションが再生される。

__AV_RECALIBRATE
　顔の向きを再キャリブレーションする。__AV_START 時に、その時点の遠隔操作者の顔の向きを正面として向きのキャリブレーションが行われる。このコマンドはそのキャリブレーションのみを再実行する。

__AVCONF_ALLOWFARCLOSEMOVE,値
　体の前後の動きをトレースするかどうかのフラグ。1ならトレースする、0なら無視する。独立に、0なら平均した回転量を両目に適用する。

__AV_TRACK,x,y,z,rx,ry,rz,eyeLrx,eyeLry,eyeLrz,eyeRrx,eyeRry,eyeRrz,flag
　頭部動作のパラメータ。頭の移動量(x,y,z)と回転量(rx,ry,rz)のあと左目と右目の回転量。移動量の単位はミリ、回転量の単位はラジアン。
　flag は目の回転量がグローバルのときに1、ローカルの時に0を指定する（OpenFace の AU の場合1, ARKit の値を使う場合は0）

__AV_ARKIT,shape=rate,shape=rate,...
　ARKit のフェイストラッキングの shape 名とその強度 [0..1] の組の集合。この値と shapemap の内容をもとにアバターの表情が制御される。 __AV_AU とは併用しない。

__AV_AU,num=rate,num=rate,...
　Action Unit の番号（1～46）とその強度 [0..1] の組の集合。この値と shapemap で定義したマッピングをもとにアバターの表情が制御される。__AV_ARKIT とは併用しない。

__AV_EXMORPH,name=rate,name=rate,...
　任意モーフの外部制御。nameで指定した名前に対応するモーフの強度を指定する。値は [0..1]。ここで使われる名前 name と実際に操作するモーフは、shapemap 内で "EXMORPH_name ボーン名" のように対応を指定する必要あり。

__AV_EXBONE,name,x,y,z,rx,ry,rz,rw,name,x,y,z,rx,ry,rz,rw,...
　任意ボーンの外部制御。nameで指定した名前に対応するボーンの移動量と回転量を指定する。単位はそれぞれミリとクォータニオン。ここで使われる名前 name と実際に操作するボーンの対応は、shapemap 内で "EXBONE_name ボーン名" のように指定する必要あり。複数の指定を1回で行える。

__AV_MESSAGE,string
　string をMMDAgent-EXの制御メッセージとして MMDAgent-EX 内へ送る。任意のメッセージを指定可能。

SNDSTRM
　以後のSNDパートを音声ストリームとみなし、VADを有効にする。（デフォルト））

SNDFILE
　以後のSNDパートをファイルチャンクとみなし、VAD を無効にする。音声ファイル送信は(1) SNDFILE送信、(2)SNDパートで音声データ送信、(3) SNDBRKS で終了信号送信、の３段階で行われる。

SNDBRKS
　送られてきている音声をここで区切る。

SNDから始まるパート
　音声データ。仕様は後述

```

## 制御開始・終了・設定

## モデル選択

## 対話アクション再生

## ヘッドトラッキング

## フェイシャルトラッキング

## ボーン個別制御

## モーフ個別制御

## 音声伝送

音声データは以下で説明する方法でエンコードして、外部操作と同じソケットへ送り込みます。以下の `xxxx` は4桁の数字で、そのあとに続くデータ本体のバイト長を10進数4桁で表します。16kHz, 16bit, mono のデータのみです。長い音声を一括で送信すると遅延が発生するので、なるべく40ms分 (1280 Bytes) ぐらいの短いセグメントで区切って逐次送信してください。

```text
１パックあたり ヘッダ7byte+本体
   文字列 "SND"   1バイト目～3バイト目
   数値 "xxxx"    4バイト目～7バイト目, decimal
   音声データ本体 8バイト目～(xxxxの値 + 7) バイト目
```

音声伝送のモードとして、ファイルモードとストリーミングモードの2種類のモードがあります。

ファイルモードでは、音声データは上記のとおり短いチャンクに区切って送信し（全体を1つの大きなチャンクとして一度に送信することも可能）、最後に発話終端信号を送ります。MMDAgent-EX は、1つ目のチャンクの受信終了と同時に音声の再生を開始して、送信された音声データを出力し、発話終端に達したらセッションの終了とリップシンクの口閉じを行います。

ストリーミングモードでは、音声送信は短チャンクごとに行う必要があります。明示的な発話終端は与えられないため、MMDAgent-EX 側で無音部分の検出から発話区間の区切りが行われます。

デフォルトはストリーミングモードです。ファイルモードにするには、まず先に `SNDFILE\n` を送信してモードを切り替えてから、ファイルの中身を逐次 `SND` で転送します。その際、ファイルの終端まで送信し終えたら `SNDBRKS\n` を送って入力終了をMMDAgent-EXに伝えます。ストリーミングモードに戻すには `SNDSTRM\n` を送信します。

