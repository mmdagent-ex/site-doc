---
title: Home
type: docs
---
# MMDAgent-EX

[[日本語](ja) | English ]

MMDAgent-EX is a research and development platform for spoken dialogue systems, multi-modal interactions and avatar communications using CG avatars. It has been open-sourced since December 2023, with [CG Avatar Gene & Uka](https://www.slp.nitech.ac.jp/en/avatar/).

> The notation can be either **MMDAgent-EX** or **MMD-Agent EX**. The "MMD" part has a double meaning, representing both "Multi-Modal Dialogue" and "MikuMikuDance". We call it “Em-Em-Dee-Agent E-X”.

This site contains all documents related to MMDAgent-EX.  If you are new, please proceed through the tutorials in order. You can also comment at the bottom of each page.

- Tutorials
- Creating Content
- Development
- Reference Manual

GitHub repositories (bug reports, requests, etc)

- [MMDAgent-EX](https://github.com/mmdagent-ex/MMDAgent-EX)
- [CG Avatar Gene](https://github.com/mmdagent-ex/gene)
- [CG Avatar Uka](https://github.com/mmdagent-ex/uka)
- [Example used on this site](https://github.com/mmdagent-ex/example)

Contact information

- Twitter/X [@MMDAgentEX](https://twitter.com/MMDAgentEX)（for announcements）
- mmdagent-ex-official@lee-lab.org (for inquiries about research, development, and licensing)
- Developed at: [Lee Laboratory, Nagoya Institute of Technology](https://www.slp.nitech.ac.jp/en/)

**Citations**

**APA**

    Lee, A. (2023). MMDAgent-EX (Version 1.0.0) [Computer software].
    https://doi.org/10.5281/zenodo.10427369

**BibTeX**

    @software{Lee_MMDAgent-EX_2023,
        author = {Lee, Akinobu},
        doi = {10.5281/zenodo.10427369},
        license = {Apache-2.0},
        month = dec,
        title = {{MMDAgent-EX}},
        url = {https://github.com/mmdagent-ex/MMDAgent-EX},
        version = {1.0.0},
        year = {2023}
    }

## See it in action (in Japanese)

Rule-based dialogue written in FST.  Whole system runs on a PC with CPU only.

{{< youtube iu2gU2uHAcc >}}